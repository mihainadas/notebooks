{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "9624ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implementarea unui Perceptron Simplu _de Mihai Dan Nadăș (mihai.nadas@ubbcluj.ro), ianuarie 2025_\n",
    "\n",
    "Acest notebook implementează o versiune a perceptronului așa cum a fost introdusă în lucrarea din 1958 a lui Frank Rosenblatt, \"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\".\n",
    "\n",
    "Vom încerca să utilizăm concepte matematice de bază, evitând algebra liniară (adică lucrul cu vectori și matrici) pe cât posibil.\n",
    "\n",
    "## Obiectiv\n",
    "\n",
    "Scopul este de a antrena un model cu două greutăți, $w_{1},\\ w_{2}$, câte una pentru fiecare dintre coordonatele $x,\\ y$ ale unui punct definit ca $(x,\\ y)$, și un bias $b$, folosind o adaptare a ecuației algebrice $y = mx + c$ a formei panta-intercepția a unei drepte.\n",
    "\n",
    "Modelul va rezolva o sarcină simplă de clasificare, a unui set de date separabil liniar pe baza următoarei funcții:\n",
    "\n",
    "$\n",
    "f: \\mathbb{N} \\to \\mathbb{N}, \\quad f(x) =\n",
    "\\begin{cases}\n",
    "x & \\text{dacă } x \\bmod 2 = 0, \\\\\n",
    "2x & \\text{dacă } x \\bmod 2 = 1.\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "## Set de date\n",
    "Mai întâi, vom genera un set de date, folosind Biblioteca Standardă Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "import random\n",
    "\n",
    "\n",
    "def generate_dataset(num_items=20, start=0, stop=100):\n",
    "    random.seed(42)\n",
    "    dataset = []\n",
    "    x1_values = set()\n",
    "    while len(dataset) < num_items:\n",
    "        x1 = random.randint(start, stop)\n",
    "        if x1 in x1_values:\n",
    "            continue\n",
    "        x1_values.add(x1)\n",
    "        x2 = x1 if x1 % 2 == 0 else 2 * x1\n",
    "        y = (\n",
    "            0 if x1 == x2 else 1\n",
    "        )  # (x1, x2) este etichetat ca fiind Clasa 0 dacă x1 este par și Clasa 1 în caz contrar\n",
    "        dataset.append((x1, x2, y))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = generate_dataset()\n",
    "\n",
    "# să împărțim acum datasetul în seturi de antrenament și test\n",
    "train_ratio = 0.8\n",
    "num_train = int(len(dataset) * train_ratio)\n",
    "dataset_train, dataset_test = dataset[:num_train], dataset[num_train:]\n",
    "print(f\"Set de antrenament (n={len(dataset_train)}): {dataset_train}\")\n",
    "print(f\"Set de test (n={len(dataset_test)}: {dataset_test}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "b369f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reprezentare Vizuală\n",
    "\n",
    "Folosind _Matplotlib_ și _pandas_, vom reprezenta vizual seturile de date de antrenament și testare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2978b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_datasets(train_dataset, test_dataset):\n",
    "    # Combină seturile de date într-un DataFrame pentru o manipulare mai ușoară\n",
    "    train_df = pd.DataFrame(train_dataset, columns=[\"x1\", \"x2\", \"class\"])\n",
    "    train_df[\"set\"] = \"Train\"\n",
    "\n",
    "    test_df = pd.DataFrame(test_dataset, columns=[\"x1\", \"x2\", \"class\"])\n",
    "    test_df[\"set\"] = \"Test\"\n",
    "\n",
    "    combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "    # Definește culorile și marcajele\n",
    "    colors = {0: \"blue\", 1: \"red\"}\n",
    "    markers = {\"Train\": \"o\", \"Test\": \"x\"}\n",
    "\n",
    "    # Plotează fiecare grup folosind Matplotlib\n",
    "    fig, ax = plt.subplots()\n",
    "    for (dataset, cls), group in combined_df.groupby([\"set\", \"class\"]):\n",
    "        ax.scatter(\n",
    "            group[\"x1\"],\n",
    "            group[\"x2\"],\n",
    "            color=colors[cls],\n",
    "            label=f\"{dataset} Dataset, Class {cls}\",\n",
    "            s=30,\n",
    "            marker=markers[dataset],\n",
    "        )\n",
    "\n",
    "    # Gestionează legenda și etichetele\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), title=\"Dataset și Clasă\", loc=\"best\")\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.set_title(\"Seturi de date pentru antrenament și testare\")\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "plot_datasets(dataset_train, dataset_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "c2368d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definirea unui Clasificator Liniar\n",
    "\n",
    "Cu dataset-ul nostru pregătit, ne îndreptăm acum atenția către fundația matematică care permite modelului nostru să clasifice o intrare $x_{1} \\text{și} x_{2}$ ca aparținând claselor $0$ sau $1$, după cum urmează:\n",
    "\n",
    "$\n",
    "c: \\mathbb{N} \\to \\{0,1\\}, \\quad\n",
    "c(x_{1},x_{2}) =\n",
    "\\begin{cases} \n",
    "1, & \\text{dacă } (x_{1},x_{2}) \\in \\text{Clasa 1}, \\\\\n",
    "0, & \\text{dacă } (x_{1},x_{2}) \\in \\text{Clasa 2}.\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "Această clasificare poate fi realizată utilizând reprezentarea algebrică a unei linii într-un sistem de coordonate cartezian, descrisă de:\n",
    "\n",
    "$\n",
    "z(x) = w_{1}x_{1}+w_{2}x_{2} + c,\n",
    "$\n",
    "\n",
    "unde:\n",
    "- $w_{1} \\text{ și } w_{2}$ reprezintă ponderile care determină panta ce reprezintă unghiul liniei rezultate față de axa $x$,\n",
    "- $c$ este termenul liber, indicând unde linia intersectează axa $y$.\n",
    "\n",
    "Din graficul reprezentat mai sus, devine clar că cele două clase sunt liniar separabile, ceea ce face adecvată utilizarea unei frontiere de separare liniară unde $w_{1} \\text{ și } w_{2}$ sunt antrenate folosind algoritmul Perceptron al lui Rosenblatt.\n",
    "\n",
    "Pentru a ilustra acest punct, iată cum ar arăta o linie definită de $w_{1}=1, w_{2}=0.5, \\text{ și } c=0$ pe imaginea noastră anterioară."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "zx = lambda x1, x2, w1, w2, c: w1 * x1 + w2 * x2 + c\n",
    "\n",
    "\n",
    "def plot_zx(w1, w2, c):\n",
    "    x2 = lambda x1: (\n",
    "        (-w1 * x1 - c) / w2 if w2 != 0 else -c / w1 if w1 != 0 else c\n",
    "    )  # acest lucru se datorează faptului că ecuația dreptei este w1*x1 + w2*x2 + c = 0, deci x2 = (-w1*x1 - c) / w2\n",
    "    x1_values = range(0, 101)\n",
    "    x2_values = [x2(x1) for x1 in x1_values]\n",
    "    plt.plot(x1_values, x2_values, label=f\"{w1}x1+{w2}x2+{c}=0\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "\n",
    "def plot_datasets_and_zx(w1, w2, c):\n",
    "    plot_datasets(dataset_train, dataset_test)\n",
    "    plot_zx(w1, w2, c)\n",
    "\n",
    "\n",
    "plot_datasets_and_zx(-1.5, 1.1, -10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "05752ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Acum, este evident că, în această configurație, punctele de date sunt separate clar. Totuși, există și modalități alternative de a configura $w_{1},\\ w_{2}, \\text{ și } c$ pentru a obține exemple mai puțin ideale. De exemplu, când $w_{1}=0.1,\\ w_{2}=0.1, \\text{ și } c=0.5$, obținem o limită de separare mai puțin ideală."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ebddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_datasets_and_zx(0.1, 0.1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "ae18eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "În acest caz particular, $z$ nu va ajuta la clasificarea niciunui punct de date.\n",
    "\n",
    "## Evaluarea performanței clasificatorului\n",
    "\n",
    "Acum că am definit $z=w_{1}x_{1}+w_{2}x_{2}+c$ ca fiind limita decizională a clasificatorului nostru, și că am stabilit vizual că funcționează pentru unele valori alese (dintre, probabil, alte opțiuni), să definim o abordare computațională pentru a determina performanța acestuia, folosind o metrică numită _acuratețe_.\n",
    "\n",
    "### Definirea clasificatorului\n",
    "\n",
    "Dar înainte de a aprofunda performanța clasificatorului nostru, să-l definim astfel:\n",
    "\n",
    "$\n",
    "c: \\mathbb{N} \\to \\{0,1\\}, \\quad\n",
    "c(x_{1},x_{2}) =\n",
    "\\begin{cases} \n",
    "1, & \\text{dacă } z(x_{1},x_{2}) >= 0, \\\\\n",
    "0, & \\text{dacă } z(x_{1},x_{2}) <0.\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "În esență, aceasta înseamnă că dacă un număr $x$ este deasupra limitei decizionale definite de $f(x)$, va fi clasificat ca $1$, altfel ca $0$.\n",
    "\n",
    "Să implementăm clasificatorul în cod și apoi să revenim la discuția despre evaluarea performanței sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e262fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = lambda x1, x2, w1, w2, c: 1 if zx(x1, x2, w1, w2, c) >= 0 else 0\n",
    "\n",
    "\n",
    "def accuracy(dataset, w1, w2, c):\n",
    "    print(f\"Se calculează acuratețea pe setul de antrenament folosind w1={w1}, w2={w2}, c={c}\")\n",
    "    correct = 0\n",
    "    for x1, x2, y in dataset:\n",
    "        if y == cx(x1, x2, w1, w2, c):\n",
    "            correct += 1\n",
    "    print(\n",
    "        f\"Acuratețea rezultată: {correct}/{len(dataset)}, adică {correct/len(dataset)*100:.2f}%\"\n",
    "    )\n",
    "    return correct / len(dataset)\n",
    "\n",
    "\n",
    "# Aplicarea funcției de acuratețe pe setul de antrenament folosind cele două seturi de greutăți și bias așa cum s-a arătat mai sus, în primul exemplu\n",
    "accuracy(dataset_train, -1.5, 1.1, -10)\n",
    "\n",
    "# Aplicarea funcției de acuratețe pe setul de antrenament folosind două seturi de greutăți și bias așa cum s-a arătat mai sus, în al doilea exemplu\n",
    "accuracy(dataset_train, 0.1, 0.1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "dd27506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Discuție despre Acuratețe\n",
    "\n",
    "Așa cum s-a arătat anterior, modificarea valorilor pentru greutăți și bias generează rezultate de acuratețe diferite. Acest lucru se datorează faptului că greutățile și biasurile distincte stabilesc limite de decizie unice care pot funcționa diferit, în funcție de cât de bine \"clasifică\" dataset-ul în clasele corecte. Provocarea constă în găsirea valorilor \"optime\" pentru acești doi parametri. Pentru a realiza acest lucru, folosim un proces cunoscut sub numele de _antrenare a modelului_.\n",
    "\n",
    "## Antrenarea Modelului\n",
    "\n",
    "Utilizând concluziile obținute din analiza noastră, vom continua acum să ne antrenăm modelul printr-o serie de iterații, rafinând valorile greutăților și biasului până când ajungem la un nivel acceptabil de acuratețe. Acest proces iterativ ne permite să găsim combinația ideală de parametri care să se potrivească cel mai bine dataset-ului nostru și sarcinii de clasificare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddaf0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mai întâi, să inițializăm ponderile și bias-ul la zero\n",
    "w1, w2, c = 0, 0, 0\n",
    "\n",
    "# Acum să definim rata de învățare\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Acum să definim numărul de epoci\n",
    "num_epochs = 100\n",
    "\n",
    "# Creăm un DataFrame pentru a stoca detaliile epocilor\n",
    "epoch_details = pd.DataFrame(columns=[\"epoch\", \"x1\", \"x2\", \"y\", \"z\", \"y_hat\", \"w1\", \"w2\", \"c\"])\n",
    "\n",
    "# Acum să începem bucla de antrenament\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoca {epoch+1}\")\n",
    "    for x1, x2, y in dataset_train:\n",
    "        z = zx(x1, x2, w1, w2, c)\n",
    "        y_hat = 1 if z >= 0 else 0\n",
    "        w1 += learning_rate * (y - y_hat) * x1\n",
    "        w2 += learning_rate * (y - y_hat) * x2\n",
    "        c += learning_rate * (y - y_hat)\n",
    "        print(f\"  x1={x1}, x2={x2}, y={y}, z={z:.2f}, y_hat={y_hat}, w1={w1:.2f}, w2={w2:.2f}, c={c:.2f}\")\n",
    "        # Adăugăm detaliile în DataFrame\n",
    "        epoch_details = epoch_details.concat({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"x1\": x1,\n",
    "            \"x2\": x2,\n",
    "            \"y\": y,\n",
    "            \"z\": z,\n",
    "            \"y_hat\": y_hat,\n",
    "            \"w1\": w1,\n",
    "            \"w2\": w2,\n",
    "            \"c\": c\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Afișăm DataFrame-ul\n",
    "epoch_details.head()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
